### 字符串编码

作者：Windson Yang
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

在打开文件或者邮件的时候，你一定会遇到像这样的字符串乱码的问题：

    É��OÇ��


学习编程的过程一定会遇到Unicode, UTF-8, ASCII, Latin-1这些编码术语。要了解字符串编码，必须要了解计算机的一些基础知识，例如字符串如何存储与表示，如果知识希望靠运气来解决或者避开它，反而会在一次次盲目的尝试中浪费更多的时间。这篇文章的每一节都非常重要，不能跳过。所以请花上15分钟静下心读吧：

![like_unicode]()

### 基本名词

#### 字符(Character）

    A B C 天 气 エ ン コ 😁

上面的用空格分割的都是单个字符，它代表对人类有意义的各种语言文字。

#### 字符串(Strings）

    Hello 天气 Hola

由多个字符组成的集合

#### 键值表(Hash Table)

一一对应的表，例如函数

    y = x * 2

每个x都有对应并且唯一的一个y值对应，x与y组成的集合就是键值表，其中一种形式：

    1 2 3
    2 4 6

这里的每一个键(1, 2, 3)都有对应的值(2, 4, 6)

#### 编码（encode）

将字符串按照一定的模式（例如某些规则，或者根据一一对应的键值表（Hash Table））转换成二进制数字，然后显示或者存储

#### 解码（decode）

与编码相反，解码把二进制数字按照一定的模式转换成字符串显示

### 计算机如何存储数据

计算机最初由西方国家设计以及发展，理所当然他们就使用了自己的语言作为常用的字符集，以英文为例，字符集包括大小写字母，数字加上一些标点符号和运算符号大概120个。因为早期的计算机存储资源非常宝贵（请自行搜索下3.5英寸软盘）。计算机科学家希望用最少的空间来存储字符。同时，计算机是使用二进制存储数据的，无论是文字，图片，数字还是其他数据，都是以数字"0"或者"1"存储起来的。举个例子，如果计算机要存储"BEE"这个字符串，它先根据一个字母与数字的转换表把字母转换成数字然后存储。我们把下面这个对应表叫做Cherry表，Cherry表使用二进制用3位就能表示8种不同的字符：

    000 001 010 011 100 101 110 111
      A   B   C   D   E   F   G   H

当我们打开文件编辑器，添加“BEE”这3个字母并保存为“BEE.txt”的时候，计算机会这样存储数据

![BEE]()

左边是数据所在的位置，右边是数据。

当另外一个使用者使用文件编辑器打开，如果它知道这些数据是通过Cherry表转换的，它就可以根据Cherry表还原原有的字符串。

    001100100

它会通过后缀名猜测这个文件是文本文件，然后会先以3位为单位分割，根据我们一开始的对应表，转换成相应的字母。

    001 100 100
      B   E   E 

不过如果你使用图片浏览器来打开这个文件，或者用文本编辑器打开一张图片的话，很可能就会看到乱码，*因为不同形式的文件有不同的对应表*，对于图片浏览器来说，"001100100"也许是对应一个红色的像素点。 至于为什么000表示的A，001代表的是B，这是设计表的作者定义的，你只需要告诉计算机这个对应关系，计算机就会知道如何转换。 *早期的计算机，字符串的表现形式和存储形式是一致的，001100100（表现形式）直接存储到硬盘中*

理解这个之后其实就很容易理解字符串编码和解码了！

![happy]()

#### 字符串编码
二进制3位只能表达8个不同的字符，明显不够存储英文一共100多个字符，最简单的解决方案就是使用更多的位来保存，2的7次方128已经足够了，加多一位用作错误检查。而且计算机更喜欢处理8位为基数的数字（我们现在的计算机一般都是64位或者32位的）所以最后选择使用8位来存储字符，刚好一个字节。8位数字对应的表就更长了：

![ascii-table]()


计算机存储“Cherry”这个字符串，就会存储下面的“0”和“1”在硬盘内，读取的时候再对照上面的表显示出来就好。

![cherry]()

    1000011 1101000 1100101 1110010 1110010 1111001
          C       h       e       r       r       y


#### ASCII编码

上面的表把

    C -> 1000011

这样的过程称为编码（encode），也就是说寻找一种模式（某些规则，或者对应表）来把字符串用二进制数字来显示并且保存。解码（decode）则相反，把二进制数字转换为字符串的过程。早期计算机科学家统一用这张表作编码，称为[ASCII编码](https://en.wikipedia.org/wiki/ASCII)。现在问题来了：

![unicode-problem]()

ASCII编码不够用，例如中文，常用字就几千个，其他亚洲语言也遇到这样的问题。所以以前国内流行的并不是ASCII编码，而是GBK编码。本质其实也一样，用两个字节，一张更大的表，用更多的位来表示字符。GBK的编码方式比较有趣，是可变长度的编码，一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字。为了兼容ASCII编码，GBK使用了单字节编码和双字节编码。也就是说当我们把“Cherry”用GBK编码存储的时候，它依然会存储为

    1000011 1101000 1100101 1110010 1110010 1111001
          C       h       e       r       r       y

*如果只存储ASCII编码出现的字符，那么解码的时候使用什么编码都不会出错*

只有当要存储一些没有出现在ASCII表中的字符，例如“Cherry 你好”，GBK编码会存储为

    1000011 1101000 1100101 1110010 1110010 1111001 100000 11000100 11100011 10111010 11000011
          C       h       e       r       r       y   空格                你                好


这时候“你”和“好”都是用两个字节保存，问题来了，如果使用GBK解码的时候，如果计算机读到ASCII出现的二进制数字，例如上面的“C”，“h”...就会用ASCII来进行解码，当遇到ASCII表中没有的二进制数字，例如当他遇到“y”后面的第一个二进制数字

    11000100

它发现在ACSCII表中招不到对应的字符（11000100代表的是十进制188），它就知道这个是两个字节组成的GBK表专有的字符，于是它把

    11000100 11100011

找到GBK编码对应的“你”然后显示出来。不过这样就会遇到我们常见的编码问题，如果一个文件用GBK编码存储起来，然后用ASCII解码，就会出错。也就是说当你用GBK编码保存了文件，然后你的朋友使用ASCII编码打开就会报错。因为ASCII表中并没有对应的字符串显示。下面以python3为例


    >>> hello = "Cherry 你好" # 定义字符串
    >>> hello_gbk = hello.encode('gb2312') # 用GBK编码把字符串转换成二进制
    >>> hello_gbk 
    # 这里是上面1的16进制表示
    # b'Cherry \xc4\xe3\xba\xc3' = 1000011 1101000 1100101 1110010 1110010 1111001 100000 11000100 11100011 10111010 11000011
    b'Cherry \xc4\xe3\xba\xc3'
    >>> hello_gbk.decode('ascii') # 如果用ASCII解码则报错，因为计算机在ASCII表中找不到对应的显示字符
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    UnicodeDecodeError: 'ascii' codec can't decode byte 0xc4 in position 7: ordinal not in range(128)

这个问题其实也容易解决，只需要在文档的信息上面添加这是用什么编码的，打开的时候选择对应的解码就好，不过另外一个问题就比较头痛，很多国家都开始使用自己的编码，例如日本使用Shift JIS，韩国使用KS X 1001。而且即使是中文，还有繁体中文，简体中文，编码经过发展也有几个不同版本。这样下去就越来越乱了，即使你知道文档里面存的是中文，也不知道用什么编码才能正确打开，有时候文档中没有包含编码信息的时候，计算机可能就会猜这是什么编码，举例

    >>> hello = "你好"
    >>> hello_gbk = hello.encode("gb2312")
    >>> hello_gbk
    b'\xc4\xe3\xba\xc3'
    >>> hello_gbk.decode("Shift-JIS")
    'ﾄ羲ﾃ'
    >>> hello_gbk.decode("utf-8")
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc4 in position 0: invalid continuation byte

在上面的例子“你好”经过GBK编码编程四个字节，之后用日本的Shift JIS版本居然也能显示出来，这个情况下虽然没有报错，但是显然不是我们想要的内容。只是Shift JIS中刚好有这四个字节对应的字符串而已，如果我们用另外一种编码UTF-8来解码，就会因为招不到对应的字符串而报错。

#### Unicode

如果你足够聪明的话，最简单解决的方法就是，用足够长的二进制位来存储世界上所有字符串。这并不是痴人说梦，Unicode就是为此而生，其实很简单，每个国家的每个字符都编进去，最新的版本已经有 136,755个字符串了。例如你好，对应的是 4F60 597D。不同于之前的其他编码，Unicode只是规定了表现形式，至于如何存储则可以使用不同的编码，这个什么意思呢，例如“你好”这个字符串，如果直接使用四个字节保存的话，那么就是UTF-32编码，UTF-32编码是定长编码。很直观，既然用四个字节表达所有字符串了，那么保存的话直接用四个字节保存就好了。这没有任何技术上的问题，而且也运行得不错吧。

#### UTF-8

UTF-8编码其实只是一种hack，因为UTF-32编码把所有字符都用四个字节保存，基本只用英文的人原本使用ASCII编码只需要一个字节，加上以前计算机的存储空间很贵，网络传输速度非常慢，平白无故增加三倍显然不乐意。于是计算机科学家开发了另外一个可变长度的编码UTF-8来存储Unicode编码。具体怎么实现呢？其实很简单，首先我们参考ASCII表，使用它所有的内容，当计算机读取到ASCII中有的内容，则按照ASCII表进行转换，然后像GBK编码一样按顺序，把一些常用的字符用两个字节来保存。少用的就保存为三个字节。所以即使你用UTF-8编码保存英文，用ASCII也能正确解码

    >>> hello = "hello"
    >>> hello.encode('utf-8')
    b'hello'
    >>> b'hello'.decode('ascii')
    'hello'

这样即使旧的电脑也能正确地解码英文


#### UTF-8与Unicode有什么关系？
Unicode虽然也是由数字组成，不过它把常用的字符也用了4个字节来保存，UTF-8是一种可变长度编码，把常用的保存为1个字节


| character     | encoding  | bits              |
| ------------- |:---------:| -----------------:|
| A             | UTF-8     |          01000001 |
| A             | UTF-16    | 00000000 01000001 |
| A             | UTF-32    | 00000000 00000000 00000000 01000001 |
